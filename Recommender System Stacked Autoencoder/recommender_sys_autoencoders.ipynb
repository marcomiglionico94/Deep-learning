{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System using  Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will create a Recommender System for movies using a Stacked Autoencoder. \n",
    "The stacked Autoencoder is composed by more than one stage of Encoding and by one stage of Decoding \n",
    "We can see the structure of the network in this picture:\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1600/1*GD1a7PRdUngdUxGQqjMVWQ.png)\n",
    "\n",
    "In particular, in this model we will use the following datasets:\n",
    "\n",
    "https://grouplens.org/datasets/movielens/1m/\n",
    "\n",
    "https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "MovieLens data sets were collected by the GroupLens Research Project\n",
    "at the University of Minnesota.\n",
    " \n",
    "This data set consists of:\n",
    " * 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    " * Each user has rated at least 20 movies. \n",
    " * Simple demographic info for the users (age, gender, occupation, zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                         Genre\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movies Data\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1', names = ['MovieID', 'Title', 'Genre' ])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  Job ZipCode\n",
       "0       1      F    1   10   48067\n",
       "1       2      M   56   16   70072\n",
       "2       3      M   25   15   55117\n",
       "3       4      M   45    7   02460\n",
       "4       5      M   25   20   55455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users Data\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1', names = ['UserID', 'Gender', 'Age', 'Job', 'ZipCode' ])\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings Data\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1', names = ['UserID', 'MovieID', 'Rating', 'Timestamp' ])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare Training Set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an holdout train test split. In particular we will use 80% of the data as training set and the remaining 20 % as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1.1  5  874965758\n",
       "0  1    2  3  876893171\n",
       "1  1    3  4  878542960\n",
       "2  1    4  3  876893119\n",
       "3  1    5  3  889751712\n",
       "4  1    7  4  875071561"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set\n",
    "training_set = pd.read_csv('ml-100k/u1.base', sep = '\\t')\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79999 entries, 0 to 79998\n",
      "Data columns (total 4 columns):\n",
      "1            79999 non-null int64\n",
      "1.1          79999 non-null int64\n",
      "5            79999 non-null int64\n",
      "874965758    79999 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the df into an array\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>887431973</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>887431883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   6  5  887431973\n",
       "0  1  10  3  875693118\n",
       "1  1  12  5  878542960\n",
       "2  1  14  5  874965706\n",
       "3  1  17  3  875073198\n",
       "4  1  20  4  887431883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set\n",
    "test_set = pd.read_csv('ml-100k/u1.test', sep = '\\t')\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 4 columns):\n",
      "1            19999 non-null int64\n",
      "6            19999 non-null int64\n",
      "5            19999 non-null int64\n",
      "887431973    19999 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 625.0 KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "n_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "n_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert the data into an array whith users in line and movies in columns. For this reason we extracted the number of users and movies. The values will be the ratings. In particular we will create a list of list, in particular a list of movie ratings for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, n_users + 1):\n",
    "        id_movies = data[:, 1][data[:,0] == id_users] # Select all the movies ID that corresponds to the user id\n",
    "        id_ratings = data[:, 2][data[:,0] == id_users] # Select all the ratings ID that corresponds to the user id\n",
    "        ratings = np.zeros(n_movies)\n",
    "        ratings[id_movies - 1] = id_ratings # id_movies start at 0\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the data into Torch Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Autoencoder Class\n",
    "class SAE(nn.Module): # Inheritance from nn.Module\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__() # Get all inherited class and methods of the parent module\n",
    "        self.fc1 = nn.Linear(n_movies, 20) # First fully connected layer with 20 neurons used as Encoder\n",
    "        self.fc2 = nn.Linear(20, 10) # Second fully connected layer with 10 neurons used as Econder\n",
    "        self.fc3 = nn.Linear(10, 20) # Third fully connected layern used as Decoder\n",
    "        self.fc4 = nn.Linear(20, n_movies) # Output layer\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x)) # First encoded vector\n",
    "        x = self.activation(self.fc2(x)) # Second encoded vector\n",
    "        x = self.activation(self.fc3(x)) # First decoded vector\n",
    "        x = self.fc4(x) # Output vector\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the autoencoder\n",
    "sae = SAE()\n",
    "metric = nn.MSELoss()\n",
    "# The decay is used to regulate the convergence by reducing the learning rate after some epcohs\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 loss: 1.0966228981741677\n",
      "epoch:2 loss: 1.0533843541728227\n",
      "epoch:3 loss: 1.0383570260862365\n",
      "epoch:4 loss: 1.0306853443218258\n",
      "epoch:5 loss: 1.026731920675691\n",
      "epoch:6 loss: 1.023879606240372\n",
      "epoch:7 loss: 1.0218176013189593\n",
      "epoch:8 loss: 1.0207395770701637\n",
      "epoch:9 loss: 1.0197838926595066\n",
      "epoch:10 loss: 1.018825840361084\n",
      "epoch:11 loss: 1.0185552086597922\n",
      "epoch:12 loss: 1.0179807298566554\n",
      "epoch:13 loss: 1.0176416490458675\n",
      "epoch:14 loss: 1.0173294490045\n",
      "epoch:15 loss: 1.017008616385241\n",
      "epoch:16 loss: 1.0166951622796632\n",
      "epoch:17 loss: 1.0165761555500215\n",
      "epoch:18 loss: 1.0164913810986287\n",
      "epoch:19 loss: 1.0164307757854514\n",
      "epoch:20 loss: 1.01610899543316\n",
      "epoch:21 loss: 1.0159623596928442\n",
      "epoch:22 loss: 1.0158065286184674\n",
      "epoch:23 loss: 1.0159547969235099\n",
      "epoch:24 loss: 1.015719993614856\n",
      "epoch:25 loss: 1.0156087229344302\n",
      "epoch:26 loss: 1.0152754981520042\n",
      "epoch:27 loss: 1.0150360320201024\n",
      "epoch:28 loss: 1.0127338757254107\n",
      "epoch:29 loss: 1.011153452175444\n",
      "epoch:30 loss: 1.0104551557340806\n",
      "epoch:31 loss: 1.008380213166617\n",
      "epoch:32 loss: 1.007986201027946\n",
      "epoch:33 loss: 1.0043817271189106\n",
      "epoch:34 loss: 1.0041433712382968\n",
      "epoch:35 loss: 1.001477869900506\n",
      "epoch:36 loss: 1.0004163820147576\n",
      "epoch:37 loss: 0.9980630739527321\n",
      "epoch:38 loss: 0.9965880344905426\n",
      "epoch:39 loss: 0.9958434662235982\n",
      "epoch:40 loss: 0.9949116079221666\n",
      "epoch:41 loss: 0.9917712029290568\n",
      "epoch:42 loss: 0.992775710814201\n",
      "epoch:43 loss: 0.987283308046948\n",
      "epoch:44 loss: 0.989677026717027\n",
      "epoch:45 loss: 0.9851177060408245\n",
      "epoch:46 loss: 0.9836130570464687\n",
      "epoch:47 loss: 0.9827660941289046\n",
      "epoch:48 loss: 0.9811844140551528\n",
      "epoch:49 loss: 0.9818135512901197\n",
      "epoch:50 loss: 0.9789869070666586\n",
      "epoch:51 loss: 0.9750585707004295\n",
      "epoch:52 loss: 0.9751641827542861\n",
      "epoch:53 loss: 0.9699434259265528\n",
      "epoch:54 loss: 0.9693489024088658\n",
      "epoch:55 loss: 0.9651035915082524\n",
      "epoch:56 loss: 0.9649428132218746\n",
      "epoch:57 loss: 0.9631076683324525\n",
      "epoch:58 loss: 0.9608381768788938\n",
      "epoch:59 loss: 0.958815566541429\n",
      "epoch:60 loss: 0.9578646632610425\n",
      "epoch:61 loss: 0.955720812646754\n",
      "epoch:62 loss: 0.9556018520200514\n",
      "epoch:63 loss: 0.9531368586988933\n",
      "epoch:64 loss: 0.9564114897436502\n",
      "epoch:65 loss: 0.9544972130028033\n",
      "epoch:66 loss: 0.9545062600890963\n",
      "epoch:67 loss: 0.9523755711839637\n",
      "epoch:68 loss: 0.9524714848953052\n",
      "epoch:69 loss: 0.9497432926456728\n",
      "epoch:70 loss: 0.9499060362527485\n",
      "epoch:71 loss: 0.9474026016398439\n",
      "epoch:72 loss: 0.9502869876294894\n",
      "epoch:73 loss: 0.9449417217833683\n",
      "epoch:74 loss: 0.9465576249734032\n",
      "epoch:75 loss: 0.9453499144464627\n",
      "epoch:76 loss: 0.945687572702236\n",
      "epoch:77 loss: 0.9424320731544039\n",
      "epoch:78 loss: 0.9440645980320814\n",
      "epoch:79 loss: 0.9409278142993647\n",
      "epoch:80 loss: 0.943604950596455\n",
      "epoch:81 loss: 0.9396998683162331\n",
      "epoch:82 loss: 0.9415301227083321\n",
      "epoch:83 loss: 0.9384319837299315\n",
      "epoch:84 loss: 0.9409638547649718\n",
      "epoch:85 loss: 0.9380128601141865\n",
      "epoch:86 loss: 0.939798909927699\n",
      "epoch:87 loss: 0.9372384757558839\n",
      "epoch:88 loss: 0.9390380619560017\n",
      "epoch:89 loss: 0.9375931334828019\n",
      "epoch:90 loss: 0.938380033537338\n",
      "epoch:91 loss: 0.9349789816477652\n",
      "epoch:92 loss: 0.9377675642472433\n",
      "epoch:93 loss: 0.9341394518686398\n",
      "epoch:94 loss: 0.9359885033039828\n",
      "epoch:95 loss: 0.9326479032196971\n",
      "epoch:96 loss: 0.9349147302382212\n",
      "epoch:97 loss: 0.9328545262880102\n",
      "epoch:98 loss: 0.9341963312462803\n",
      "epoch:99 loss: 0.9321065710601757\n",
      "epoch:100 loss: 0.9337123076120116\n",
      "epoch:101 loss: 0.9316690848384352\n",
      "epoch:102 loss: 0.932991196619649\n",
      "epoch:103 loss: 0.9313205314500851\n",
      "epoch:104 loss: 0.9325301090404856\n",
      "epoch:105 loss: 0.9304352707864492\n",
      "epoch:106 loss: 0.9319924526825971\n",
      "epoch:107 loss: 0.9296110070755326\n",
      "epoch:108 loss: 0.9313580945987553\n",
      "epoch:109 loss: 0.9290586348247424\n",
      "epoch:110 loss: 0.9307253666907348\n",
      "epoch:111 loss: 0.9286961264246166\n",
      "epoch:112 loss: 0.9300014872732847\n",
      "epoch:113 loss: 0.9281010997068151\n",
      "epoch:114 loss: 0.9292621841609462\n",
      "epoch:115 loss: 0.9270078529108674\n",
      "epoch:116 loss: 0.9284316888014118\n",
      "epoch:117 loss: 0.9270419873164973\n",
      "epoch:118 loss: 0.9279859112046653\n",
      "epoch:119 loss: 0.9262641793345786\n",
      "epoch:120 loss: 0.9273117108509158\n",
      "epoch:121 loss: 0.9252104566516952\n",
      "epoch:122 loss: 0.9267069311082681\n",
      "epoch:123 loss: 0.9253095549052119\n",
      "epoch:124 loss: 0.9261138141301914\n",
      "epoch:125 loss: 0.9247339028358237\n",
      "epoch:126 loss: 0.9257788465950952\n",
      "epoch:127 loss: 0.9242844061103055\n",
      "epoch:128 loss: 0.9253501975212746\n",
      "epoch:129 loss: 0.9239837671866438\n",
      "epoch:130 loss: 0.9247713658046737\n",
      "epoch:131 loss: 0.9230289891264953\n",
      "epoch:132 loss: 0.9243418600061873\n",
      "epoch:133 loss: 0.9227144576706666\n",
      "epoch:134 loss: 0.9236691498884679\n",
      "epoch:135 loss: 0.9222312557213399\n",
      "epoch:136 loss: 0.9229051427000525\n",
      "epoch:137 loss: 0.9218802141026438\n",
      "epoch:138 loss: 0.9226591129964142\n",
      "epoch:139 loss: 0.9213889440989003\n",
      "epoch:140 loss: 0.9221419219046585\n",
      "epoch:141 loss: 0.92078266306139\n",
      "epoch:142 loss: 0.9215375333065241\n",
      "epoch:143 loss: 0.9206064165509499\n",
      "epoch:144 loss: 0.9211414316224418\n",
      "epoch:145 loss: 0.9202320724131955\n",
      "epoch:146 loss: 0.9207037497744094\n",
      "epoch:147 loss: 0.9196946566380438\n",
      "epoch:148 loss: 0.919950354351017\n",
      "epoch:149 loss: 0.9192658193613759\n",
      "epoch:150 loss: 0.9194336029327262\n",
      "epoch:151 loss: 0.9189635185036445\n",
      "epoch:152 loss: 0.9189646758138236\n",
      "epoch:153 loss: 0.9181169904929445\n",
      "epoch:154 loss: 0.9187490314379769\n",
      "epoch:155 loss: 0.9180413228818797\n",
      "epoch:156 loss: 0.9183184376466984\n",
      "epoch:157 loss: 0.9174939615732094\n",
      "epoch:158 loss: 0.917838553342555\n",
      "epoch:159 loss: 0.9168398337824563\n",
      "epoch:160 loss: 0.9173762055993786\n",
      "epoch:161 loss: 0.9167525066026186\n",
      "epoch:162 loss: 0.9170090608192836\n",
      "epoch:163 loss: 0.9163093289119456\n",
      "epoch:164 loss: 0.9167369247048682\n",
      "epoch:165 loss: 0.9156143282320265\n",
      "epoch:166 loss: 0.9164454037016614\n",
      "epoch:167 loss: 0.9157580852586387\n",
      "epoch:168 loss: 0.9157664194323102\n",
      "epoch:169 loss: 0.9149986801123181\n",
      "epoch:170 loss: 0.9152904011302918\n",
      "epoch:171 loss: 0.9150083870897998\n",
      "epoch:172 loss: 0.9150773550043405\n",
      "epoch:173 loss: 0.9144601126735797\n",
      "epoch:174 loss: 0.9144951597307917\n",
      "epoch:175 loss: 0.9140679552622603\n",
      "epoch:176 loss: 0.9139720431847275\n",
      "epoch:177 loss: 0.9141555572180019\n",
      "epoch:178 loss: 0.9136521770919174\n",
      "epoch:179 loss: 0.9138175851145861\n",
      "epoch:180 loss: 0.9134621478059178\n",
      "epoch:181 loss: 0.9132415502586612\n",
      "epoch:182 loss: 0.9130918710324907\n",
      "epoch:183 loss: 0.9130831497290337\n",
      "epoch:184 loss: 0.9129006420951674\n",
      "epoch:185 loss: 0.9127841705044398\n",
      "epoch:186 loss: 0.9125136908084185\n",
      "epoch:187 loss: 0.9126482243807088\n",
      "epoch:188 loss: 0.912241618486021\n",
      "epoch:189 loss: 0.9121563220156644\n",
      "epoch:190 loss: 0.9117491518131905\n",
      "epoch:191 loss: 0.9119145294282676\n",
      "epoch:192 loss: 0.9116601045791488\n",
      "epoch:193 loss: 0.9117280001751462\n",
      "epoch:194 loss: 0.9112378628575467\n",
      "epoch:195 loss: 0.91145536281224\n",
      "epoch:196 loss: 0.9108428474809271\n",
      "epoch:197 loss: 0.9111660918560819\n",
      "epoch:198 loss: 0.910438921710993\n",
      "epoch:199 loss: 0.910753824111879\n",
      "epoch:200 loss: 0.9103365139369824\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0 \n",
    "    s = 0. # count the number of users who rated at least one movie\n",
    "    for id_user in range(n_users): # For each user take the movies rated\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) # Batch of a single input vector\n",
    "        target = input.clone() # The target vector will be our input\n",
    "        if torch.sum(target.data > 0) > 0 : # consider users that rated at least one movie\n",
    "            output = sae.forward(input) # forward the input in the network\n",
    "            target.require_grad = False # Don't compute the gradient with respect to the target\n",
    "            output[target == 0] = 0  # Optimization since these value will not be used we put them to 0\n",
    "            loss = metric(output, target) # Compute the loss between prediction(output) and the target\n",
    "            mean_corrector = n_movies / float(torch.sum(target.data > 0) + 10e-10) # to be sure that the denominator is not 0\n",
    "            loss.backward() # Backward method for deciding the direction of th eupdate if increase or decrease\n",
    "            train_loss += np.sqrt(loss.data[0] * mean_corrector) # Update the train loss\n",
    "            s += 1. # increment users count \n",
    "            optimizer.step() # Decide the intensity of the update\n",
    "    print('epoch:' + str(epoch) +  ' loss: ' + str(train_loss / s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9196047966139437\n"
     ]
    }
   ],
   "source": [
    "# Measure the test loss\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(n_users): # For each user take the movies rated\n",
    "     # Here we keep the training set, since we need to predict the movie the user didn't watch\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]) # The target vector will be the test set\n",
    "    if torch.sum(target.data > 0) > 0 : # consider users that rated at least one movie\n",
    "        output = sae.forward(input) # forward the input in the network\n",
    "        target.require_grad = False # Don't compute the gradient with respect to the target\n",
    "        output[target == 0] = 0  # Optimization since these value will not be used we put them to 0\n",
    "        loss = metric(output, target) # Compute the loss between prediction(output) and the target\n",
    "        mean_corrector = n_movies / float(torch.sum(target.data > 0) + 10e-10) # to be sure that the denominator is not 0\n",
    "        test_loss += np.sqrt(loss.data[0] * mean_corrector) # Update the train loss\n",
    "        s += 1. # increment users count \n",
    "print('Test loss: ' + str(test_loss / s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test loss is very similar to the training loss. This mean that our model is robust and that there is no overfitting.\n",
    "In general the goal was to obtain a test loss of less than one, and with this autoencoder we "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
